# -*- coding: utf-8 -*-

import os
import sys
import json
import math
import asyncio
import base64
from jinja2 import Environment, FileSystemLoader, select_autoescape
import config as cfg
from utils import sanitize_filename

# å°è¯•å¯¼å…¥requests
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False
    requests = None


# æ¯ä¸ªè¯ç‹¬ç«‹çš„è´¡çŒ®è€…é¢œè‰²
WORD_COLORS = [
    '#DC2626', '#EA580C', '#D97706', '#CA8A04', '#65A30D',
    '#16A34A', '#0D9488', '#0891B2', '#2563EB', '#7C3AED'
]

# æ¦œå•é…ç½® (title, key, icon, unit)
RANKING_CONFIG = [
    ('ç¾¤èŠå™ªéŸ³', 'è¯ç—¨æ¦œ', 'ğŸ†', 'æ¡'),
    ('æ‰“å­—æ°‘å·¥', 'å­—æ•°æ¦œ', 'ğŸ“', 'å­—'),
    ('å°ä½œæ–‡ç‹‚', 'é•¿æ–‡ç‹', 'ğŸ“–', ''),
    ('è¡¨æƒ…ç‹‚äºº', 'è¡¨æƒ…å¸', 'ğŸ˜‚', 'ä¸ª'),
    ('æˆ‘çš„å›¾å›¾', 'å›¾ç‰‡ç‹‚é­”', 'ğŸ–¼ï¸', 'å¼ '),
    ('è½¬å‘æœºå™¨', 'åˆå¹¶è½¬å‘ç‹', 'ğŸ“¦', 'æ¬¡'),
    ('å›å¤åŠ³æ¨¡', 'å›å¤ç‹‚', 'ğŸ’¬', 'æ¬¡'),
    ('å›å¤é»‘æ´', 'è¢«å›å¤æœ€å¤š', 'â­', 'æ¬¡'),
    ('è‰¾ç‰¹ç‹‚é­”', 'è‰¾ç‰¹ç‹‚', 'ğŸ“¢', 'æ¬¡'),
    ('äººæ°”é¶å­', 'è¢«è‰¾ç‰¹æœ€å¤š', 'ğŸ¯', 'æ¬¡'),
    ('é“¾æ¥ä»“é¼ ', 'é“¾æ¥åˆ†äº«ç‹', 'ğŸ”—', 'æ¡'),
    ('é˜´é—´ä½œæ¯', 'æ·±å¤œå…š', 'ğŸŒ™', 'æ¡'),
    ('æ—©å…«æ€¨ç§', 'æ—©èµ·é¸Ÿ', 'ğŸŒ…', 'æ¡'),
    ('å¤è¯»æœºå™¨', 'å¤è¯»æœº', 'ğŸ”„', 'æ¬¡'),
]


def format_number(value):
    """æ ¼å¼åŒ–æ•°å­—"""
    try:
        return f"{int(value):,}"
    except:
        return str(value)


def truncate_text(text, length=50):
    """æˆªæ–­æ–‡æœ¬"""
    if not text:
        return ""
    text = text.replace('\n', ' ').strip()
    if len(text) > length:
        return text[:length] + '...'
    return text


def get_avatar_url(uin):
    """è·å–QQå¤´åƒURL"""
    return f"https://q1.qlogo.cn/g?b=qq&nk={uin}&s=640"


def download_image_to_base64(url, timeout=10, retry=2):
    """
    ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
    
    Args:
        url: å›¾ç‰‡URL
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        retry: é‡è¯•æ¬¡æ•°
        
    Returns:
        base64ç¼–ç çš„å›¾ç‰‡æ•°æ®ï¼Œå¤±è´¥è¿”å›None
    """
    if not REQUESTS_AVAILABLE:
        return None
    
    if not url or not url.startswith('http'):
        return None
    
    # è®¾ç½®User-Agentï¼Œé¿å…è¢«æ‹’ç»
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://qzone.qq.com/',
        'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8'
    }
    
    # ç¦ç”¨SSLè­¦å‘Šï¼ˆå¦‚æœéœ€è¦ï¼‰
    try:
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    except:
        pass
    
    for attempt in range(retry + 1):
        try:
            response = requests.get(url, timeout=timeout, stream=True, headers=headers, verify=True)
            if response.status_code == 200:
                # æ£€æŸ¥å†…å®¹é•¿åº¦
                content = response.content
                if len(content) < 100:  # å¤ªå°çš„å†…å®¹å¯èƒ½æ˜¯é”™è¯¯é¡µé¢
                    if attempt < retry:
                        continue
                    return None
                
                image_data = base64.b64encode(content).decode('utf-8')
                # æ£€æµ‹å›¾ç‰‡ç±»å‹
                content_type = response.headers.get('Content-Type', 'image/png')
                if 'jpeg' in content_type or 'jpg' in content_type:
                    return f"data:image/jpeg;base64,{image_data}"
                elif 'gif' in content_type:
                    return f"data:image/gif;base64,{image_data}"
                elif 'webp' in content_type:
                    return f"data:image/webp;base64,{image_data}"
                else:
                    return f"data:image/png;base64,{image_data}"
            elif response.status_code == 404:
                # 404ç›´æ¥è¿”å›ï¼Œä¸éœ€è¦é‡è¯•
                return None
        except requests.exceptions.Timeout:
            if attempt < retry:
                continue
            return None
        except requests.exceptions.RequestException:
            if attempt < retry:
                continue
            return None
        except Exception:
            if attempt < retry:
                continue
            return None
    
    return None


def clean_ai_response(text):
    # æ¸…ç†AIå“åº”ä¸­çš„æ€è€ƒè¿‡ç¨‹æ ‡è®°
    if not text:
        return text
    
    import re
    
    # ç§»é™¤å¸¸è§çš„æ€è€ƒæ ‡è®°æ¨¡å¼
    patterns = [
        r'\*Thinking[:\.].*?\*.*?(?=\n\n|\Z)', 
        r'\*\*Examining.*?\*\*.*?(?=\n\n|\Z)',  
        r'<thinking>.*?</thinking>',  
        r'ã€æ€è€ƒã€‘.*?ã€/æ€è€ƒã€‘',  
        r'\[æ€è€ƒè¿‡ç¨‹\].*?(?=\n\n|\Z)',  
    ]
    
    cleaned = text
    for pattern in patterns:
        cleaned = re.sub(pattern, '', cleaned, flags=re.DOTALL | re.IGNORECASE)
    
    # å¦‚æœæ•´æ®µéƒ½æ˜¯thinkingå†…å®¹ï¼Œå°è¯•æå–æœ€åä¸€è¡Œä½œä¸ºç»“è®º
    if cleaned.strip() == '' or len(cleaned.strip()) < 5:
        lines = [l.strip() for l in text.split('\n') if l.strip()]
        # å°è¯•æ‰¾åˆ°ä¸æ˜¯thinkingæ ‡è®°çš„æœ€åå‡ è¡Œ
        for line in reversed(lines):
            if not any(marker in line.lower() for marker in ['thinking', 'examining', 'æ€è€ƒ', 'analysis']):
                if len(line) > 5 and len(line) < 100:  # åˆç†é•¿åº¦
                    return line
    
    return cleaned.strip()


class AIWordSelector:
    """AIæ™ºèƒ½é€‰è¯å™¨"""
    
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¾¤èŠæ–‡åŒ–åˆ†æå¸ˆï¼Œæ“…é•¿è¯†åˆ«æœ€å…·ä»£è¡¨æ€§çš„ç¾¤èŠçƒ­è¯ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ä»å€™é€‰è¯åˆ—è¡¨ä¸­é€‰å‡º10ä¸ªæœ€é€‚åˆä½œä¸ºå¹´åº¦çƒ­è¯çš„è¯æ±‡ã€‚

## é€‰è¯æ ‡å‡†ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰ï¼š
1. **å¨±ä¹æ„ä¹‰**ï¼šè¯æ±‡è¦æœ‰è¶£å‘³æ€§ã€æœ‰æ¢—ã€èƒ½å¼•å‘å…±é¸£æˆ–ç¬‘ç‚¹
2. **ç¾¤èŠç‰¹è‰²**ï¼šä½“ç°è¿™ä¸ªç¾¤ç‹¬ç‰¹æ°›å›´ã€æ–‡åŒ–ã€é»‘è¯æˆ–å†…éƒ¨æ¢—
3. **ä½¿ç”¨é¢‘ç‡**ï¼šåœ¨ä¿è¯æœ‰æ„ä¹‰çš„å‰æä¸‹ï¼Œä¼˜å…ˆé€‰æ‹©é«˜é¢‘è¯
4. **ç½‘ç»œæµè¡Œ**ï¼šç½‘ç»œçƒ­è¯ã€æµè¡Œæ¢—ã€è°éŸ³æ¢—ç­‰ä¼˜å…ˆ
5. **è¡¨è¾¾ä»·å€¼**ï¼šè¯æ±‡è¦æœ‰å®é™…è¡¨è¾¾æ„ä¹‰ï¼Œä¸æ˜¯çº¯ç²¹çš„åŠŸèƒ½è¯

## å¿…é¡»è¿‡æ»¤çš„æ— æ„ä¹‰è¯æ±‡ç±»å‹ï¼š
- **åŠŸèƒ½è¯**ï¼šå¥½çš„ã€ä¸æ˜¯ã€æ²¡æœ‰ã€ä¼šã€ç°åœ¨ã€ä½†æ˜¯ã€ç„¶åã€æ‰€ä»¥ã€å› ä¸ºç­‰
- **è¯­æ°”è¯**ï¼šå•Šã€å‘€ã€å‘¢ã€å§ã€å—ã€å“¦ã€å—¯ã€å“ˆç­‰ï¼ˆé™¤éåœ¨ç‰¹å®šè¯­å¢ƒä¸‹ç‰¹åˆ«æœ‰è¶£ï¼‰
- **ä»£è¯**ï¼šæˆ‘ã€ä½ ã€ä»–ã€è¿™ã€é‚£ç­‰
- **å¸¸è§å‰¯è¯**ï¼šå¾ˆã€éå¸¸ã€ç‰¹åˆ«ã€ä¹Ÿã€è¿˜ã€å°±ã€æ‰ã€éƒ½ç­‰
- **æ— å®é™…æ„ä¹‰çš„è¯**ï¼šåœ¨ã€æœ‰ã€æ˜¯ã€ä¸Šã€ä¸‹ã€ä¸­ã€é‡Œç­‰

## ä¼˜å…ˆé€‰æ‹©çš„è¯æ±‡ç±»å‹ï¼š
- ç½‘ç»œæµè¡Œæ¢—ã€çƒ­è¯ã€è¡¨æƒ…åŒ…ç›¸å…³è¯æ±‡
- ç¾¤å†…ç‰¹æœ‰çš„é»‘è¯ã€ç¼©å†™ã€æš—å·
- æç¬‘è¡¨æƒ…ã€emojiç»„åˆ
- æœ‰è¶£çš„å£å¤´ç¦…ã€å£å¤´è¡¨è¾¾
- ç‹¬ç‰¹çš„è¡¨è¾¾æ–¹å¼ã€è°éŸ³æ¢—
- æœ‰ç‰¹è‰²çš„è„è¯ã€ç²—è¯ï¼ˆå¦‚æœæœ‰ç¾¤èŠæ–‡åŒ–ç‰¹è‰²ï¼‰
- èƒ½ä»£è¡¨ç¾¤å†…è¯é¢˜ã€æ´»åŠ¨çš„è¯æ±‡

## è¯„ä¼°æ–¹æ³•ï¼š
å¯¹äºæ¯ä¸ªå€™é€‰è¯ï¼Œè¯·è¯„ä¼°ï¼š
1. **å¨±ä¹ä»·å€¼**ï¼ˆ0-10åˆ†ï¼‰ï¼šæ˜¯å¦æœ‰è¶£ã€æœ‰æ¢—ã€èƒ½å¼•å‘å…±é¸£
2. **ç¾¤èŠç‰¹è‰²**ï¼ˆ0-10åˆ†ï¼‰ï¼šæ˜¯å¦ä½“ç°ç¾¤å†…ç‹¬ç‰¹æ–‡åŒ–
3. **è¡¨è¾¾æ„ä¹‰**ï¼ˆ0-10åˆ†ï¼‰ï¼šæ˜¯å¦æœ‰å®é™…è¡¨è¾¾ä»·å€¼ï¼Œä¸æ˜¯çº¯ç²¹åŠŸèƒ½è¯
4. **ä½¿ç”¨é¢‘ç‡**ï¼šä½œä¸ºå‚è€ƒï¼Œä½†ä¸æ˜¯å”¯ä¸€æ ‡å‡†

**é‡è¦**ï¼šå³ä½¿ä¸€ä¸ªè¯ä½¿ç”¨é¢‘ç‡å¾ˆé«˜ï¼Œå¦‚æœå®ƒåªæ˜¯"å¥½çš„"ã€"ä¸æ˜¯"è¿™ç±»æ— æ„ä¹‰åŠŸèƒ½è¯ï¼Œä¹Ÿåº”è¯¥è¢«è¿‡æ»¤æ‰ã€‚ä¼˜å…ˆé€‰æ‹©é¢‘ç‡ä¸­ç­‰ä½†å¨±ä¹ä»·å€¼é«˜çš„è¯ï¼Œè€Œä¸æ˜¯é¢‘ç‡é«˜ä½†æ— æ„ä¹‰çš„è¯ã€‚

è¯·ä»æä¾›çš„å€™é€‰è¯ä¸­é€‰å‡ºæœ€èƒ½ä»£è¡¨è¿™ä¸ªç¾¤èŠæ–‡åŒ–çš„10ä¸ªè¯ã€‚"""

    def __init__(self):
        self.client = None
        self.model = None
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        # æ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
        api_key = os.getenv('OPENAI_API_KEY', cfg.OPENAI_API_KEY)
        base_url = os.getenv('OPENAI_BASE_URL', cfg.OPENAI_BASE_URL)
        self.model = os.getenv('OPENAI_MODEL', cfg.OPENAI_MODEL)
        
        if not api_key or api_key == "sk-your-api-key-here":
            print("âš ï¸ æœªé…ç½®OpenAI API Keyï¼Œæ— æ³•ä½¿ç”¨AIé€‰è¯")
            return
        
        if not self.model:
            print("âš ï¸ æœªé…ç½®OpenAIæ¨¡å‹")
            return
        
        try:
            from openai import OpenAI
            import httpx
            
            self.client = OpenAI(
                api_key=api_key,
                base_url=base_url,
                http_client=httpx.Client(timeout=120.0)
            )
            print(f"âœ… AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {self.model})")
        except Exception as e:
            print(f"âš ï¸ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def select_words(self, candidate_words, top_n=200):
        """ä»å€™é€‰è¯ä¸­æ™ºèƒ½é€‰å‡º10ä¸ªå¹´åº¦çƒ­è¯"""
        if not self.client:
            print("âŒ AIæœªå¯ç”¨ï¼Œè¯·é…ç½®OpenAI API Key")
            return None
        
        # å‡†å¤‡å€™é€‰è¯åˆ—è¡¨ï¼ˆå–å‰top_nä¸ªï¼‰
        candidates = candidate_words[:top_n]
        
        # è·å–æ— æ„ä¹‰è¯åˆ—è¡¨ï¼Œç”¨äºAIå‚è€ƒ
        meaningless_words = list(cfg.FUNCTION_WORDS)[:50]  # å–å‰50ä¸ªä½œä¸ºç¤ºä¾‹
        meaningless_examples = 'ã€'.join(meaningless_words[:20])  # æ˜¾ç¤ºå‰20ä¸ªä½œä¸ºç¤ºä¾‹
        
        # æ„å»ºå€™é€‰è¯ä¿¡æ¯ï¼ŒåŒ…å«æ›´å¤šä¸Šä¸‹æ–‡
        words_info = []
        for idx, word_data in enumerate(candidates, 1):
            word = word_data['word']
            freq = word_data['freq']
            samples = word_data.get('samples', [])
            
            # æä¾›æ›´å¤šæ ·æœ¬ä¸Šä¸‹æ–‡ï¼ˆæœ€å¤š3ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæœ€å¤š40å­—ç¬¦ï¼‰
            sample_texts = []
            for sample in samples[:3]:
                if sample:
                    sample_texts.append(sample[:40])
            
            if sample_texts:
                samples_preview = ' | '.join(sample_texts)
            else:
                samples_preview = 'æ— æ ·æœ¬'
            
            # è®¡ç®—é¢‘ç‡æ’åï¼ˆç”¨äºAIå‚è€ƒï¼‰
            rank_info = f"æ’å#{idx}"
            
            words_info.append(f"{idx}. {word} ({freq}æ¬¡, {rank_info}) - ä½¿ç”¨ç¤ºä¾‹: {samples_preview}")
        
        words_text = '\n'.join(words_info)
        
        user_prompt = f"""è¯·ä»ä»¥ä¸‹{len(candidates)}ä¸ªå€™é€‰è¯ä¸­é€‰å‡º10ä¸ªæœ€é€‚åˆä½œä¸ºå¹´åº¦çƒ­è¯çš„è¯æ±‡ï¼š

{words_text}

## é€‰è¯è¦æ±‚ï¼š
1. **ä¸¥æ ¼è¿‡æ»¤æ— æ„ä¹‰è¯æ±‡**ï¼šå¿…é¡»æ’é™¤ä»¥ä¸‹ç±»å‹çš„è¯ï¼ˆç³»ç»Ÿå·²é…ç½®çš„æ— æ„ä¹‰è¯ç¤ºä¾‹ï¼š{meaningless_examples}ç­‰ï¼‰ï¼š
   - åŠŸèƒ½è¯ï¼šå¥½çš„ã€ä¸æ˜¯ã€æ²¡æœ‰ã€ä¼šã€ç°åœ¨ã€ä½†æ˜¯ã€ç„¶åã€æ‰€ä»¥ã€å› ä¸ºã€ä»¥åŠã€æˆ–è€…
   - å¸¸è§è¯­æ°”è¯ï¼šå•Šã€å‘€ã€å‘¢ã€å§ã€å—ã€å“¦ã€å—¯ã€å“ˆï¼ˆé™¤éåœ¨ä¾‹å¥ä¸­ç‰¹åˆ«æœ‰è¶£æˆ–æœ‰ç‰¹æ®Šå«ä¹‰ï¼‰
   - ä»£è¯ï¼šæˆ‘ã€ä½ ã€ä»–ã€è¿™ã€é‚£ã€è¿™ä¸ªã€é‚£ä¸ª
   - æ— æ„ä¹‰å‰¯è¯ï¼šå¾ˆã€éå¸¸ã€ç‰¹åˆ«ã€ä¹Ÿã€è¿˜ã€å°±ã€æ‰ã€éƒ½ã€å…¨ã€åªã€ä»…
   - æ— å®é™…æ„ä¹‰çš„è¯ï¼šåœ¨ã€æœ‰ã€æ˜¯ã€ä¸Šã€ä¸‹ã€ä¸­ã€é‡Œã€å†…ã€å¤–ã€å‰ã€å
   
   **åˆ¤æ–­æ ‡å‡†**ï¼šå¦‚æœä¸€ä¸ªè¯åªæ˜¯è¯­æ³•åŠŸèƒ½è¯ï¼Œæ²¡æœ‰å®é™…è¡¨è¾¾æ„ä¹‰æˆ–å¨±ä¹ä»·å€¼ï¼Œå°±åº”è¯¥è¢«è¿‡æ»¤ã€‚å³ä½¿é¢‘ç‡å¾ˆé«˜ï¼Œä¹Ÿè¦ä¼˜å…ˆé€‰æ‹©é¢‘ç‡ä¸­ç­‰ä½†æœ‰è¶£çš„è¯ã€‚

2. **ä¼˜å…ˆé€‰æ‹©æ ‡å‡†**ï¼ˆæŒ‰é‡è¦æ€§ï¼‰ï¼š
   - æœ‰å¨±ä¹ä»·å€¼ã€æœ‰æ¢—ã€æœ‰è¶£çš„è¯
   - ä½“ç°ç¾¤èŠç‰¹è‰²ã€å†…éƒ¨æ–‡åŒ–çš„è¯
   - ç½‘ç»œæµè¡Œæ¢—ã€çƒ­è¯
   - ç¾¤å†…é»‘è¯ã€ç¼©å†™ã€æš—å·
   - æœ‰ç‰¹è‰²çš„è¡¨è¾¾æ–¹å¼

3. **ä½¿ç”¨é¢‘ç‡**ï¼š
   - åœ¨ä¿è¯æœ‰æ„ä¹‰çš„å‰æä¸‹ï¼Œä¼˜å…ˆé€‰æ‹©é«˜é¢‘è¯
   - ä½†å¦‚æœé«˜é¢‘è¯éƒ½æ˜¯æ— æ„ä¹‰çš„åŠŸèƒ½è¯ï¼Œå®æ„¿é€‰æ‹©é¢‘ç‡ä¸­ç­‰ä½†æœ‰è¶£çš„è¯
   - ä¸è¦ä»…ä»…å› ä¸ºé¢‘ç‡é«˜å°±é€‰æ‹©æ— æ„ä¹‰çš„è¯

4. **è¾“å‡ºæ ¼å¼**ï¼š
   - ç›´æ¥è¾“å‡º10ä¸ªåºå·ï¼Œç”¨é€—å·åˆ†éš”
   - ä¾‹å¦‚: 1,5,8,12,15,23,30,42,56,78
   - åªè¾“å‡ºåºå·ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—æˆ–è§£é‡Š

5. **é€‰è¯ç­–ç•¥**ï¼š
   - ä¼˜å…ˆä»å‰100ä¸ªè¯ä¸­é€‰æ‹©ï¼ˆå› ä¸ºé¢‘ç‡é€šå¸¸æ›´é«˜ï¼‰
   - ä½†å¦‚æœåé¢çš„è¯ç‰¹åˆ«æœ‰è¶£æˆ–æœ‰ç‰¹è‰²ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©
   - ç¡®ä¿é€‰å‡ºçš„10ä¸ªè¯éƒ½æœ‰å®é™…æ„ä¹‰å’Œå¨±ä¹ä»·å€¼

è¯·ä»”ç»†åˆ†ææ¯ä¸ªè¯çš„å¨±ä¹æ„ä¹‰å’Œç¾¤èŠç‰¹è‰²ï¼Œä¸¥æ ¼è¿‡æ»¤æ— æ„ä¹‰è¯æ±‡ï¼Œé€‰å‡ºæœ€èƒ½ä»£è¡¨è¿™ä¸ªç¾¤èŠæ–‡åŒ–çš„10ä¸ªè¯ã€‚"""

        try:
            print("ğŸ¤– AIæ­£åœ¨åˆ†æå¹¶é€‰æ‹©å¹´åº¦çƒ­è¯...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=100,
                temperature=0.7
            )
            
            # æ¸…ç†å“åº”ä¸­çš„æ€è€ƒè¿‡ç¨‹
            raw_result = response.choices[0].message.content.strip()
            result = clean_ai_response(raw_result)
            
            # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹ç»“æœ
            if not result:
                result = raw_result
            
            print(f"   AIè¿”å›: {result}")
            
            # è§£æåºå·
            indices = []
            for part in result.replace('ï¼Œ', ',').split(','):
                try:
                    idx = int(part.strip())
                    if 1 <= idx <= len(candidates):
                        indices.append(idx - 1)  # è½¬ä¸º0ç´¢å¼•
                except:
                    continue
            
            if len(indices) < 10:
                print(f"âš ï¸ AIåªé€‰å‡º{len(indices)}ä¸ªè¯ï¼Œè‡ªåŠ¨è¡¥å……æœ‰æ„ä¹‰çš„é«˜é¢‘è¯...")
                # è¡¥å……å‰é¢çš„è¯ç›´åˆ°10ä¸ªï¼Œä½†è·³è¿‡æ— æ„ä¹‰è¯
                for i in range(len(candidates)):
                    if i not in indices and len(indices) < 10:
                        candidate_word = candidates[i]['word']
                        # è·³è¿‡æ— æ„ä¹‰è¯
                        if candidate_word not in cfg.FUNCTION_WORDS and candidate_word not in cfg.BLACKLIST:
                            indices.append(i)
            
            indices = indices[:10]
            selected = [candidates[i] for i in indices]
            
            # äºŒæ¬¡éªŒè¯ï¼šæ£€æŸ¥é€‰å‡ºçš„è¯æ˜¯å¦åŒ…å«æ— æ„ä¹‰è¯æ±‡
            filtered_selected = []
            replaced_count = 0
            for word_data in selected:
                word = word_data['word']
                # æ£€æŸ¥æ˜¯å¦åœ¨æ— æ„ä¹‰è¯åˆ—è¡¨ä¸­
                if word in cfg.FUNCTION_WORDS or word in cfg.BLACKLIST:
                    print(f"   âš ï¸ AIé€‰å‡ºäº†æ— æ„ä¹‰è¯ '{word}'ï¼Œè‡ªåŠ¨æ›¿æ¢...")
                    replaced_count += 1
                    # ä»å€™é€‰è¯ä¸­æ‰¾ä¸€ä¸ªä¸åœ¨å·²é€‰åˆ—è¡¨ä¸­çš„æœ‰æ„ä¹‰è¯æ›¿æ¢
                    for candidate in candidates:
                        if candidate['word'] not in [w['word'] for w in filtered_selected + selected]:
                            if candidate['word'] not in cfg.FUNCTION_WORDS and candidate['word'] not in cfg.BLACKLIST:
                                filtered_selected.append(candidate)
                                break
                else:
                    filtered_selected.append(word_data)
            
            # å¦‚æœæ›¿æ¢äº†è¯ï¼Œè¡¥å……åˆ°10ä¸ª
            if replaced_count > 0:
                print(f"   â„¹ï¸ å·²æ›¿æ¢ {replaced_count} ä¸ªæ— æ„ä¹‰è¯")
                # ä»å‰©ä½™å€™é€‰è¯ä¸­è¡¥å……
                for candidate in candidates:
                    if len(filtered_selected) >= 10:
                        break
                    if candidate['word'] not in [w['word'] for w in filtered_selected]:
                        if candidate['word'] not in cfg.FUNCTION_WORDS and candidate['word'] not in cfg.BLACKLIST:
                            filtered_selected.append(candidate)
            
            filtered_selected = filtered_selected[:10]
            
            print("\nâœ… AIé€‰è¯å®Œæˆ:")
            for i, word_data in enumerate(filtered_selected, 1):
                print(f"   {i}. {word_data['word']} ({word_data['freq']}æ¬¡)")
            
            return filtered_selected
            
        except Exception as e:
            print(f"âŒ AIé€‰è¯å¤±è´¥: {e}")
            return None


class AIUserPersonalityGenerator:
    """AIç¾¤å‹æ€§æ ¼å’Œç”¨è¯é”è¯„ç”Ÿæˆå™¨"""
    
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªå¹½é»˜é£è¶£çš„ç¾¤èŠåˆ†æå¸ˆï¼Œæ“…é•¿é€šè¿‡åˆ†æç¾¤å‹çš„ç”¨è¯ä¹ æƒ¯æ¥é”è¯„å…¶æ€§æ ¼ç‰¹ç‚¹ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ä¸ºç¾¤å‹ç”Ÿæˆä¸€å¥ç²¾è¾Ÿçš„æ€§æ ¼å’Œç”¨è¯é”è¯„ã€‚è¦æ±‚ï¼š
1. ç®€çŸ­æœ‰åŠ›ï¼Œ20-40å­—ä¸ºå®œ
2. ç»“åˆè¯¥ç¾¤å‹çš„5ä¸ªä»£è¡¨æ€§è¯æ±‡ï¼Œåˆ†æå…¶å‘è¨€é£æ ¼å’Œæ€§æ ¼ç‰¹ç‚¹
3. å¯ä»¥è°ƒä¾ƒã€å¯ä»¥æ„Ÿæ…¨ã€å¯ä»¥å“²ç†ï¼Œä½†è¦æœ‰è¶£ä¸”å‡†ç¡®
4. è¯­æ°”å¯ä»¥æ˜¯ï¼šæ¯’èˆŒåæ§½/æ¸©æƒ…æ„Ÿæ…¨/å“²å­¦æ€è€ƒ/å†·å¹½é»˜/è°éŸ³æ¢— ç­‰
5. ä¸è¦å¤ªæ­£ç»ï¼Œè¦æœ‰ç½‘æ„Ÿ
6. è¦ä½“ç°å‡ºè¯¥ç¾¤å‹çš„ç‹¬ç‰¹ä¹‹å¤„ï¼Œä¸èƒ½æ˜¯é€šç”¨è¯„ä»·

é£æ ¼å‚è€ƒï¼š
- å¦‚æœè¯æ±‡åæŠ€æœ¯å‘ â†’ "ä»£ç æ˜¯ä»–çš„ç¬¬äºŒè¯­è¨€ï¼Œé”®ç›˜æ˜¯ä»–çš„æ­¦å™¨"
- å¦‚æœè¯æ±‡åæç¬‘å‘ â†’ "è¡Œèµ°çš„è¡¨æƒ…åŒ…åˆ¶é€ æœºï¼Œç¾¤èŠçš„å¿«ä¹æºæ³‰"
- å¦‚æœè¯æ±‡åæ–‡è‰ºå‘ â†’ "ç”¨è¯å¦‚è¯—ï¼Œæ¯ä¸€å¥éƒ½æ˜¯å¯¹ç”Ÿæ´»çš„æ¸©æŸ”æ³¨è§£"
- å¦‚æœè¯æ±‡åæš´èºå‘ â†’ "æƒ…ç»ªç®¡ç†å¤§å¸ˆï¼Œç”¨è¯å¦‚åˆ€ï¼Œå¥å¥è§è¡€"
- å¦‚æœè¯æ±‡åä½›ç³» â†’ "å²æœˆé™å¥½ä»£è¨€äººï¼Œç”¨è¯å¦‚ç¦…ï¼Œå¿ƒå¦‚æ­¢æ°´"
"""

    def __init__(self):
        self.client = None
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆæ”¯æŒOpenAIå…¼å®¹çš„APIï¼Œå¦‚DeepSeekï¼‰"""
        # æ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
        api_key = os.getenv('OPENAI_API_KEY', cfg.OPENAI_API_KEY)
        base_url = os.getenv('OPENAI_BASE_URL', cfg.OPENAI_BASE_URL)
        self.model = os.getenv('OPENAI_MODEL', cfg.OPENAI_MODEL)
        
        if not api_key or api_key == "sk-your-api-key-here":
            print("âš ï¸ æœªé…ç½®OpenAI API Keyï¼Œå°†è·³è¿‡AIç¾¤å‹é”è¯„")
            return
        
        if not self.model:
            print("âš ï¸ æœªé…ç½®AIæ¨¡å‹ï¼Œå°†è·³è¿‡AIç¾¤å‹é”è¯„")
            return
        
        try:
            from openai import OpenAI
            import httpx
            
            self.client = OpenAI(
                api_key=api_key,
                base_url=base_url if base_url else None,
                http_client=httpx.Client(timeout=60.0)
            )
        except Exception as e:
            print(f"âš ï¸ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def generate_personality_comment(self, user_name, representative_words, user_stats=None):
        """ä¸ºå•ä¸ªç¾¤å‹ç”Ÿæˆæ€§æ ¼å’Œç”¨è¯é”è¯„"""
        if not self.client:
            return self._fallback_comment(user_name, representative_words)
        
        # æ„å»ºè¯æ±‡ä¿¡æ¯
        words_text = 'ã€'.join([f"{w['word']}({w['count']}æ¬¡)" for w in representative_words])
        
        # æ„å»ºç”¨æˆ·æç¤º
        stats_text = ""
        if user_stats:
            stats_text = f"""
å‘è¨€ç»Ÿè®¡ï¼š
- æ€»å‘è¨€æ•°ï¼š{user_stats.get('message_count', 0)}æ¡
- æ€»å­—æ•°ï¼š{user_stats.get('char_count', 0)}å­—
- å¹³å‡æ¯æ¡ï¼š{user_stats.get('avg_chars_per_msg', 0):.1f}å­—
"""
        
        user_prompt = f"""è¯·ä¸ºè¿™ä¸ªç¾¤å‹ç”Ÿæˆä¸€å¥æ€§æ ¼å’Œç”¨è¯é”è¯„ï¼š

ç¾¤å‹åç§°ï¼š{user_name}
ä»£è¡¨æ€§è¯æ±‡ï¼ˆ5ä¸ªï¼‰ï¼š{words_text}
{stats_text}

è¯·ç»“åˆè¿™5ä¸ªè¯æ±‡çš„ç‰¹ç‚¹ï¼Œåˆ†æè¯¥ç¾¤å‹çš„å‘è¨€é£æ ¼å’Œæ€§æ ¼ç‰¹å¾ï¼Œç”Ÿæˆä¸€å¥ç²¾è¾Ÿçš„é”è¯„ã€‚
ç›´æ¥è¾“å‡ºé”è¯„å†…å®¹ï¼Œä¸è¦åŠ å¼•å·æˆ–å…¶ä»–æ ¼å¼ã€‚"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=200,
                temperature=0.8
            )
            
            raw_content = response.choices[0].message.content.strip()
            cleaned_content = clean_ai_response(raw_content)
            
            if not cleaned_content or len(cleaned_content) < 5:
                return self._fallback_comment(user_name, representative_words)
            
            return cleaned_content
        except Exception as e:
            print(f"   âš ï¸ AIç”Ÿæˆå¤±è´¥({user_name}): {e}")
            return self._fallback_comment(user_name, representative_words)
    
    def _fallback_comment(self, user_name, representative_words):
        """å¤‡ç”¨é”è¯„"""
        words_list = [w['word'] for w in representative_words]
        words_str = 'ã€'.join(words_list[:3])
        return f"ç”¨è¯å¦‚{words_list[0] if words_list else 'è°œ'}ï¼Œé£æ ¼ç‹¬ç‰¹ï¼Œç¾¤èŠä¸­çš„{words_list[1] if len(words_list) > 1 else 'ç‹¬ç‰¹'}å­˜åœ¨"
    
    def generate_batch(self, users_data):
        """æ‰¹é‡ç”Ÿæˆç¾¤å‹é”è¯„"""
        if not self.client:
            print("âš ï¸ AIæœªå¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤ç¾¤å‹é”è¯„")
            return {u['name']: self._fallback_comment(u['name'], u['words']) for u in users_data}
        
        print("ğŸ¤– æ­£åœ¨ç”ŸæˆAIç¾¤å‹æ€§æ ¼é”è¯„...")
        comments = {}
        for i, user_info in enumerate(users_data, 1):
            user_name = user_info['name']
            print(f"   [{i}/{len(users_data)}] {user_name}...", end=' ')
            comment = self.generate_personality_comment(
                user_name,
                user_info['words'],
                user_info.get('stats')
            )
            comments[user_name] = comment
            print(f"âœ“")
        
        return comments


class AICommentGenerator:
    """AIé”è¯„ç”Ÿæˆå™¨"""
    
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªå¹½é»˜é£è¶£çš„ç¾¤èŠåˆ†æå¸ˆï¼Œæ“…é•¿ç”¨çŠ€åˆ©åˆä¸å¤±æ¸©åº¦çš„è¯­è¨€ç‚¹è¯„ç½‘ç»œçƒ­è¯ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ä¸ºQQç¾¤å¹´åº¦çƒ­è¯æŠ¥å‘Šç”Ÿæˆä¸€å¥ç²¾è¾Ÿçš„é”è¯„ã€‚è¦æ±‚ï¼š
1. ç®€çŸ­æœ‰åŠ›ï¼Œ15-30å­—ä¸ºå®œ
2. å¯ä»¥è°ƒä¾ƒã€å¯ä»¥æ„Ÿæ…¨ã€å¯ä»¥å“²ç†ï¼Œä½†è¦æœ‰è¶£
3. ç»“åˆè¯è¯­æœ¬èº«çš„å«ä¹‰å’Œä½¿ç”¨åœºæ™¯
4. è¯­æ°”å¯ä»¥æ˜¯ï¼šæ¯’èˆŒåæ§½/æ¸©æƒ…æ„Ÿæ…¨/å“²å­¦æ€è€ƒ/å†·å¹½é»˜/è°éŸ³æ¢— ç­‰
5. ä¸è¦å¤ªæ­£ç»ï¼Œè¦æœ‰ç½‘æ„Ÿ

é£æ ¼å‚è€ƒï¼š
- "å“ˆå“ˆå“ˆ" â†’ "å¿«ä¹æ˜¯å‡çš„ï¼Œä½†æ•·è¡æ˜¯çœŸçš„"
- "ç‰›é€¼" â†’ "è¯æ±‡é‡å‘Šæ€¥æ—¶çš„å”¯ä¸€å‡ºè·¯"
- "å¥½çš„" â†’ "æˆå¹´äººæœ€æ•·è¡çš„ä¸‰ä¸ªå­—"
- "?" â†’ "ä¸€ä¸ªç¬¦å·ï¼Œåä¸‡ç§è´¨ç–‘"
- "6" â†’ "å½“ä»£ç½‘å‹æœ€é«˜æ•ˆçš„èµç¾"""

    def __init__(self):
        self.client = None
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆæ”¯æŒOpenAIå…¼å®¹çš„APIï¼Œå¦‚DeepSeekï¼‰"""
        # æ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
        api_key = os.getenv('OPENAI_API_KEY', cfg.OPENAI_API_KEY)
        base_url = os.getenv('OPENAI_BASE_URL', cfg.OPENAI_BASE_URL)
        self.model = os.getenv('OPENAI_MODEL', cfg.OPENAI_MODEL)
        
        if not api_key or api_key == "sk-your-api-key-here":
            print("âš ï¸ æœªé…ç½®OpenAI API Keyï¼Œå°†è·³è¿‡AIé”è¯„")
            return
        
        if not self.model:
            print("âš ï¸ æœªé…ç½®AIæ¨¡å‹ï¼Œå°†è·³è¿‡AIé”è¯„")
            return
        
        try:
            from openai import OpenAI
            import httpx
            
            self.client = OpenAI(
                api_key=api_key,
                base_url=base_url if base_url else None,  # å¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨é»˜è®¤
                http_client=httpx.Client(timeout=60.0)  # å¢åŠ è¶…æ—¶
            )
            
            # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
            api_provider = "DeepSeek" if "deepseek" in (base_url or "").lower() else "OpenAI"
            print(f"âœ… AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ ({api_provider}, æ¨¡å‹: {self.model})")
            
            # è°ƒè¯•ä¿¡æ¯
            if os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy'):
                print("ğŸŒ ç³»ç»Ÿä»£ç†å·²è‡ªåŠ¨åŠ è½½")
                
        except Exception as e:
            print(f"âš ï¸ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def generate_comment(self, word, freq, samples):
        """ä¸ºå•ä¸ªè¯ç”Ÿæˆé”è¯„"""
        if not self.client:
            return self._fallback_comment(word)
        
        # æ„å»ºç”¨æˆ·æç¤º
        samples_text = '\n'.join(f'- {s[:50]}' for s in samples[:5]) if samples else 'æ— '
        
        user_prompt = f"""è¯·ä¸ºè¿™ä¸ªç¾¤èŠçƒ­è¯ç”Ÿæˆä¸€å¥é”è¯„ï¼š

è¯è¯­ï¼š{word}
å‡ºç°æ¬¡æ•°ï¼š{freq}æ¬¡
ä½¿ç”¨æ ·æœ¬ï¼š
{samples_text}

ç›´æ¥è¾“å‡ºé”è¯„å†…å®¹ï¼Œä¸è¦åŠ å¼•å·æˆ–å…¶ä»–æ ¼å¼ã€‚"""

        try:
            # å°è¯•è°ƒç”¨APIï¼Œå¦‚æœå¤±è´¥åˆ™é™çº§å¤„ç†
            response = self.client.chat.completions.create(
                model=self.model,  # ä½¿ç”¨å®ä¾‹å˜é‡
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=150,
                temperature=0.8
            )
            
            # æ¸…ç†å“åº”ä¸­çš„æ€è€ƒè¿‡ç¨‹
            raw_content = response.choices[0].message.content.strip()
            cleaned_content = clean_ai_response(raw_content)
            
            # å¦‚æœæ¸…ç†åä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œä½¿ç”¨å¤‡ç”¨
            if not cleaned_content or len(cleaned_content) < 5:
                return self._fallback_comment(word)
            
            return cleaned_content
        except Exception as e:
            print(f"   âš ï¸ AIç”Ÿæˆå¤±è´¥({word}): {e}")
            return self._fallback_comment(word)
    
    def _fallback_comment(self, word):
        """å¤‡ç”¨é”è¯„"""
        fallbacks = [
            "ç¾¤å‹çš„å¿«ä¹ï¼Œç®€å•åˆçº¯ç²¹",
            "è¿™ä¸ªè¯æ‰¿è½½äº†å¤ªå¤šæ•…äº‹",
            "é«˜é¢‘å‡ºç°ï¼Œå¿…æœ‰åŸå› ",
            "ç¾¤èŠç²¾åï¼Œæµ“ç¼©äºæ­¤",
            "æ¯ä¸€æ¬¡ä½¿ç”¨éƒ½æ˜¯ä¸€æ¬¡è®¤åŒ",
        ]
        import random
        return random.choice(fallbacks)
    
    def generate_batch(self, words_data):
        """æ‰¹é‡ç”Ÿæˆé”è¯„"""
        if not self.client:
            print("âš ï¸ AIæœªå¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é”è¯„")
            return {w['word']: self._fallback_comment(w['word']) for w in words_data}
        
        print("ğŸ¤– æ­£åœ¨ç”ŸæˆAIé”è¯„...")
        comments = {}
        for i, word_info in enumerate(words_data, 1):
            word = word_info['word']
            print(f"   [{i}/{len(words_data)}] {word}...", end=' ')
            comment = self.generate_comment(
                word, 
                word_info['freq'], 
                word_info.get('samples', [])
            )
            comments[word] = comment
            print(f"âœ“")
        
        return comments


class ImageGenerator:
    """å›¾ç‰‡æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, analyzer=None, json_path=None, output_dir=None):
        self.analyzer = analyzer
        self.json_data = None
        self.selected_words = []
        self.ai_comments = {}
        self.user_personality_comments = {}  # ç¾¤å‹æ€§æ ¼é”è¯„
        self.user_representative_words = []  # ç¾¤å‹ä»£è¡¨æ€§è¯æ±‡
        self.output_dir = output_dir or os.path.dirname(os.path.abspath(cfg.INPUT_FILE))
        # ç¾¤å‹åˆ†æå•ç‹¬ä¿å­˜åˆ°ä¸€ä¸ªæ–‡ä»¶å¤¹
        self.personality_output_dir = os.path.join(self.output_dir, 'ç¾¤å‹åˆ†æ')
        os.makedirs(self.personality_output_dir, exist_ok=True)
        self.template_dir = os.path.join(os.path.dirname(__file__), 'templates')
        
        if json_path and os.path.exists(json_path):
            with open(json_path, 'r', encoding='utf-8') as f:
                self.json_data = json.load(f)
        elif analyzer:
            self.json_data = analyzer.export_json()
        
        self.enabled = cfg.ENABLE_IMAGE_EXPORT
        self.ai_selector = None
    
    def display_words_for_selection(self):
        """å±•ç¤ºè¯æ±‡ä¾›ç”¨æˆ·é€‰æ‹©"""
        if not self.json_data:
            print("âŒ æ— æ•°æ®å¯å±•ç¤º")
            return False
        
        top_words = self.json_data.get('topWords', [])
        if not top_words:
            print("âŒ æ— çƒ­è¯æ•°æ®")
            return False
        
        print("\n" + "=" * 70)
        print("ğŸ“ è¯·ä»ä»¥ä¸‹çƒ­è¯ä¸­é€‰æ‹© 10 ä¸ªä½œä¸ºå¹´åº¦çƒ­è¯")
        print("=" * 70)
        
        page_size = 50
        total_pages = (len(top_words) + page_size - 1) // page_size
        current_page = 0
        
        while True:
            start = current_page * page_size
            end = min(start + page_size, len(top_words))
            
            print(f"\nğŸ“„ ç¬¬ {current_page + 1}/{total_pages} é¡µ ({start + 1}-{end})")
            print("-" * 70)
            
            for i in range(start, end):
                word_info = top_words[i]
                word = word_info['word']
                freq = word_info['freq']
                samples = word_info.get('samples', [])
                
                sample_preview = samples[0].replace('\n', ' ')[:25] + '...' if samples and len(samples[0]) > 25 else (samples[0].replace('\n', ' ') if samples else 'æ— æ ·æœ¬')
                contributors = word_info.get('contributors', [])
                contrib_str = contributors[0]['name'] if contributors else 'æœªçŸ¥'
                
                print(f"  {i+1:>3}. {word:<8} ({freq:>4}æ¬¡) ğŸ‘¤{contrib_str:<10} | {sample_preview}")
            
            print("-" * 70)
            print("ğŸ“Œ [n]ä¸‹ä¸€é¡µ [p]ä¸Šä¸€é¡µ [v åºå·]è¯¦æƒ… [s]é€‰æ‹© [q]é€€å‡º")
            
            cmd = input(">>> ").strip().lower()
            
            if cmd == 'n':
                current_page = min(current_page + 1, total_pages - 1)
            elif cmd == 'p':
                current_page = max(current_page - 1, 0)
            elif cmd == 's':
                return self._get_user_selection(top_words)
            elif cmd.startswith('v'):
                try:
                    idx = int(cmd[1:].strip()) - 1
                    if 0 <= idx < len(top_words):
                        self._show_word_detail(top_words[idx], idx + 1)
                except:
                    print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆåºå·")
            elif cmd == 'q':
                return False
        
        return False
    
    def _show_word_detail(self, word_info, idx):
        """æ˜¾ç¤ºè¯æ±‡è¯¦æƒ…"""
        print(f"\n{'='*60}")
        print(f"ã€{idx}ã€‘{word_info['word']} - {word_info['freq']}æ¬¡")
        print(f"{'='*60}")
        
        contributors = word_info.get('contributors', [])
        if contributors:
            print("\nğŸ‘¤ è´¡çŒ®è€…:")
            max_count = contributors[0]['count']
            for i, c in enumerate(contributors[:5], 1):
                bar = 'â–ˆ' * int(c['count'] / max_count * 20)
                print(f"   {i}. {c['name']:<12} {bar} {c['count']}æ¬¡")
        
        samples = word_info.get('samples', [])
        if samples:
            print(f"\nğŸ“‹ æ ·æœ¬:")
            for i, s in enumerate(samples[:5], 1):
                print(f"   {i}. {s.replace(chr(10), ' ')[:60]}")
        
        input("\næŒ‰å›è½¦ç»§ç»­...")
    
    def _get_user_selection(self, top_words):
        """è·å–ç”¨æˆ·é€‰æ‹©"""
        print("\n" + "=" * 60)
        print("ğŸ“ è¾“å…¥10ä¸ªåºå· (ç©ºæ ¼/é€—å·åˆ†éš”ï¼Œæ”¯æŒèŒƒå›´å¦‚1-5)")
        
        while True:
            selection = input("\n>>> ").strip()
            if not selection:
                continue
            
            indices = []
            for part in selection.replace(',', ' ').replace('ï¼Œ', ' ').split():
                try:
                    if '-' in part:
                        start, end = map(int, part.split('-'))
                        indices.extend(range(start - 1, end))
                    else:
                        indices.append(int(part) - 1)
                except:
                    pass
            
            indices = [i for i in indices if 0 <= i < len(top_words)]
            indices = list(dict.fromkeys(indices))  # å»é‡ä¿åº
            
            if len(indices) < 10:
                print(f"âš ï¸ éœ€è¦10ä¸ªï¼Œå½“å‰{len(indices)}ä¸ª: {[i+1 for i in indices]}")
                continue
            
            indices = indices[:10]
            self.selected_words = [top_words[i] for i in indices]
            
            print("\nâœ… å·²é€‰:")
            for i, w in enumerate(self.selected_words, 1):
                print(f"   {i}. {w['word']} ({w['freq']}æ¬¡)")
            
            if input("\nç¡®è®¤? [Y/n]: ").strip().lower() in ('', 'y', 'yes'):
                return True
    
    def _prepare_template_data(self):
        """å‡†å¤‡æ¨¡æ¿æ•°æ®"""
        max_freq = max(w['freq'] for w in self.selected_words)
        min_freq = min(w['freq'] for w in self.selected_words)
        
        def calc_bar_height(freq):
            if max_freq == min_freq:
                return 80
            normalized = (freq - min_freq) / (max_freq - min_freq)
            return 25 + math.sqrt(normalized) * 75
        
        processed_words = []
        for idx, word_info in enumerate(self.selected_words):
            contributors = word_info.get('contributors', [])
            total = word_info['freq']
            
            # æ¯ä¸ªè¯ç‹¬ç«‹åˆ†é…é¢œè‰²ç»™å…¶è´¡çŒ®è€…
            segments = []
            accounted = 0
            word_contributor_colors = {}
            
            for i, c in enumerate(contributors[:5]):
                color = WORD_COLORS[i % len(WORD_COLORS)]
                word_contributor_colors[c['name']] = color
                percent = (c['count'] / total * 100) if total > 0 else 0
                segments.append({
                    'name': c['name'],
                    'uin': c.get('uin', ''),
                    'count': c['count'],
                    'percent': percent,
                    'color': color
                })
                accounted += c['count']
            
            # å…¶ä»–
            if accounted < total:
                other = total - accounted
                segments.append({
                    'name': 'å…¶ä»–',
                    'uin': '',
                    'count': other,
                    'percent': (other / total * 100),
                    'color': '#6B7280'
                })
            
            # å›¾ä¾‹ï¼ˆè¯¥è¯çš„è´¡çŒ®è€…ï¼‰
            legend = []
            for c in contributors[:3]:
                legend.append({
                    'name': c['name'], 
                    'color': word_contributor_colors.get(c['name'], '#6B7280')
                })
            while len(legend) < 3:
                legend.append({'name': '', 'color': 'transparent'})            
            # ä¸»è¦è´¡çŒ®è€…æ–‡æœ¬
            contrib_text = 'ã€'.join(c['name'] for c in contributors[:3]) if contributors else 'æœªçŸ¥'
            
            # AIé”è¯„
            ai_comment = self.ai_comments.get(word_info['word'], '')
            
            processed_words.append({
                'word': word_info['word'],
                'freq': word_info['freq'],
                'bar_height': calc_bar_height(word_info['freq']),
                'segments': segments,
                'legend': legend,
                'samples': word_info.get('samples', []),
                'contributors_text': contrib_text,
                'top_contributor': contributors[0] if contributors else None,
                'ai_comment': ai_comment,
                'color': WORD_COLORS[idx % len(WORD_COLORS)]
            })
        
        # æ¦œå•æ•°æ®
        rankings_data = self.json_data.get('rankings', {})
        processed_rankings = []
        
        # ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·è·å¾—ç¬¬ä¸€åçš„æ¬¡æ•°
        from collections import defaultdict
        first_place_count = defaultdict(int)  # {uin: count}
        first_place_honors = defaultdict(list)  # {uin: [honor_info]}
        
        for title, key, icon, unit in RANKING_CONFIG:
            data = rankings_data.get(key, [])
            if not data:
                continue
            
            first = data[0] if data else None
            others = data[1:5] if len(data) > 1 else []
            
            # ç»Ÿè®¡ç¬¬ä¸€å
            if first and first.get('uin'):
                uin = first.get('uin')
                first_place_count[uin] += 1
                first_place_honors[uin].append({
                    'title': title,
                    'icon': icon,
                    'unit': unit,
                    'value': first.get('value', 0)
                })
            
            processed_rankings.append({
                'title': title,
                'icon': icon,
                'unit': unit,
                'first': {
                    'name': first.get('name', 'æœªçŸ¥'),
                    'uin': first.get('uin', ''),
                    'value': first.get('value', 0),
                    'avatar': get_avatar_url(first.get('uin', '')) if first else ''
                } if first else None,
                'others': [
                    {
                        'name': item.get('name', 'æœªçŸ¥'),
                        'value': item.get('value', 0),
                        'uin': item.get('uin', ''),
                        'avatar': get_avatar_url(item.get('uin', ''))
                    }
                    for item in others
                ]
            })
        
        # æ‰¾å‡ºç¾¤ç¥äººï¼ˆè·å¾—ç¬¬ä¸€åæœ€å¤šçš„ç”¨æˆ·ï¼‰
        champion = None
        if first_place_count:
            champion_uin = max(first_place_count.items(), key=lambda x: x[1])[0]
            champion_count = first_place_count[champion_uin]
            champion_honors = first_place_honors[champion_uin]
            
            # è·å–ç¾¤ç¥äººçš„åŸºæœ¬ä¿¡æ¯ï¼ˆä»ä»»æ„ä¸€ä¸ªæ¦œå•ä¸­è·å–ï¼‰
            for ranking in processed_rankings:
                if ranking['first'] and ranking['first'].get('uin') == champion_uin:
                    champion = {
                        'name': ranking['first']['name'],
                        'uin': champion_uin,
                        'avatar': ranking['first']['avatar'],
                        'first_place_count': champion_count,
                        'honors': champion_honors
                    }
                    break
        
        # 24å°æ—¶åˆ†å¸ƒ
        hour_dist = self.json_data.get('hourDistribution', {})
        max_hour = max((int(hour_dist.get(str(h), 0)) for h in range(24)), default=1)
        peak_hour = max(range(24), key=lambda h: int(hour_dist.get(str(h), 0)))
        
        hour_data = []
        for h in range(24):
            count = int(hour_dist.get(str(h), 0))
            height = max((count / max_hour * 100) if max_hour > 0 else 0, 3)
            hour_data.append({'hour': h, 'count': count, 'height': height})
        
        # å¤„ç†ç¾¤å‹ä»£è¡¨æ€§è¯æ±‡å’Œé”è¯„
        processed_users = []
        for user_info in self.user_representative_words:
            user_name = user_info['name']
            personality_comment = self.user_personality_comments.get(user_name, '')
            
            processed_users.append({
                'name': user_name,
                'uin': user_info.get('uin', ''),
                'avatar': get_avatar_url(user_info.get('uin', '')),
                'words': user_info['words'],
                'stats': user_info.get('stats', {}),
                'personality_comment': personality_comment
            })
        
        return {
            'chat_name': self.json_data.get('chatName', 'æœªçŸ¥ç¾¤èŠ'),
            'message_count': self.json_data.get('messageCount', 0),
            'selected_words': processed_words,
            'rankings': processed_rankings,
            'champion': champion,  # ç¾¤ç¥äººä¿¡æ¯
            'hour_data': hour_data,
            'peak_hour': peak_hour,
            'user_personalities': processed_users  # ç¾¤å‹æ€§æ ¼é”è¯„
        }
    
    def _generate_ai_comments(self, enable_ai=False):
        """ç”ŸæˆAIé”è¯„ï¼ˆå¯é™é»˜ï¼‰"""
        ai_gen = AICommentGenerator()
        if enable_ai and ai_gen.client:
            self.ai_comments = ai_gen.generate_batch(self.selected_words)
        else:
            self.ai_comments = {w['word']: ai_gen._fallback_comment(w['word']) 
                              for w in self.selected_words}
    
    def _generate_user_personality_comments(self, enable_ai=False):
        """ç”Ÿæˆç¾¤å‹æ€§æ ¼å’Œç”¨è¯é”è¯„"""
        # ä»analyzerè·å–ç¾¤å‹ä»£è¡¨æ€§è¯æ±‡
        if self.analyzer:
            self.user_representative_words = self.analyzer.get_user_representative_words(
                top_n_users=10, 
                words_per_user=5
            )
        else:
            # å¦‚æœæ²¡æœ‰analyzerï¼Œå°è¯•ä»json_dataä¸­è·å–ï¼ˆéœ€è¦é¢å¤–å¤„ç†ï¼‰
            self.user_representative_words = []
        
        if not self.user_representative_words:
            return
        
        # ç”ŸæˆAIé”è¯„
        ai_gen = AIUserPersonalityGenerator()
        if enable_ai and ai_gen.client:
            self.user_personality_comments = ai_gen.generate_batch(self.user_representative_words)
        else:
            self.user_personality_comments = {
                u['name']: ai_gen._fallback_comment(u['name'], u['words']) 
                for u in self.user_representative_words
            }
    
    def generate_html(self):
        """ç”ŸæˆHTML"""
        if not self.selected_words:
            print("âŒ æœªé€‰æ‹©çƒ­è¯")
            return None
        
        if not os.path.exists(self.template_dir):
            os.makedirs(self.template_dir)
        
        template_path = os.path.join(self.template_dir, 'report_template.html')
        if not os.path.exists(template_path):
            print(f"âŒ æ¨¡æ¿ä¸å­˜åœ¨: {template_path}")
            return None
        
        env = Environment(
            loader=FileSystemLoader(self.template_dir),
            autoescape=select_autoescape(['html'])
        )
        env.filters['format_number'] = format_number
        env.filters['truncate_text'] = truncate_text
        env.filters['avatar_url'] = get_avatar_url
        
        template = env.get_template('report_template.html')
        data = self._prepare_template_data()
        html_content = template.render(**data)
        
        safe_name = sanitize_filename(self.json_data.get('chatName', 'æœªçŸ¥'))
        html_path = os.path.join(self.output_dir, f"{safe_name}_å¹´åº¦çƒ­è¯æŠ¥å‘Š.html")
        
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… HTML: {html_path}")
        return html_path
    
    async def _html_to_image_async(self, html_path, output_path):
        """å¼‚æ­¥è½¬å›¾ç‰‡ - é«˜åˆ†è¾¨ç‡"""
        try:
            from playwright.async_api import async_playwright
        except ImportError:
            print("âŒ éœ€è¦: pip install playwright && playwright install chromium")
            return None
        
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            # ä½¿ç”¨ device_scale_factor=3 æé«˜åˆ†è¾¨ç‡ï¼ˆ3å€ï¼‰
            context = await browser.new_context(
                viewport={'width': 450, 'height': 800},
                device_scale_factor=3,  # é«˜æ¸…æˆªå›¾
                ignore_https_errors=True
            )
            page = await context.new_page()
            
            # è®¾ç½®è¯·æ±‚æ‹¦æˆªï¼Œç¡®ä¿å¤–éƒ¨å›¾ç‰‡å¯ä»¥åŠ è½½
            async def handle_route(route):
                request = route.request
                # å¯¹äºå›¾ç‰‡è¯·æ±‚ï¼Œç¡®ä¿å…è®¸åŠ è½½
                if request.resource_type == 'image':
                    await route.continue_()
                else:
                    await route.continue_()
            
            await page.route('**/*', handle_route)
            
            # ä½¿ç”¨ file:// åè®®åŠ è½½æœ¬åœ°HTML
            file_url = f'file://{os.path.abspath(html_path).replace(os.sep, "/")}'
            await page.goto(file_url, wait_until='domcontentloaded', timeout=30000)
            
            # ç­‰å¾…æ‰€æœ‰å›¾ç‰‡çœŸæ­£åŠ è½½å®Œæˆï¼ˆåŒ…æ‹¬å¤´åƒï¼‰
            print("   ç­‰å¾…å›¾ç‰‡åŠ è½½...")
            try:
                # æ›´å®Œå–„çš„å›¾ç‰‡åŠ è½½ç­‰å¾…é€»è¾‘
                await page.evaluate("""
                    async () => {
                        const images = Array.from(document.images);
                        const promises = images.map((img, index) => {
                            return new Promise((resolve) => {
                                // å¦‚æœå›¾ç‰‡å·²ç»åŠ è½½å®Œæˆ
                                if (img.complete && img.naturalHeight !== 0) {
                                    resolve();
                                    return;
                                }
                                
                                // ç›‘å¬åŠ è½½æˆåŠŸ
                                img.onload = () => resolve();
                                
                                // ç›‘å¬åŠ è½½å¤±è´¥ï¼ˆä¹Ÿç»§ç»­ï¼Œé¿å…å¡ä½ï¼‰
                                img.onerror = () => {
                                    console.warn('å›¾ç‰‡åŠ è½½å¤±è´¥:', img.src);
                                    resolve();
                                };
                                
                                // è¶…æ—¶ä¿æŠ¤ï¼ˆ5ç§’ï¼‰
                                setTimeout(() => {
                                    console.warn('å›¾ç‰‡åŠ è½½è¶…æ—¶:', img.src);
                                    resolve();
                                }, 5000);
                                
                                // å¦‚æœsrcä¸ºç©ºæˆ–æ— æ•ˆï¼Œç«‹å³resolve
                                if (!img.src || img.src === 'undefined' || img.src.startsWith('data:')) {
                                    resolve();
                                }
                            });
                        });
                        
                        await Promise.all(promises);
                        
                        // é¢å¤–ç­‰å¾…ç¡®ä¿æ¸²æŸ“å®Œæˆ
                        await new Promise(resolve => setTimeout(resolve, 500));
                    }
                """)
            except Exception as e:
                print(f"   å›¾ç‰‡åŠ è½½ç­‰å¾…å‡ºç°å¼‚å¸¸ï¼ˆç»§ç»­æ‰§è¡Œï¼‰: {e}")
            
            # ç­‰å¾…ç½‘ç»œç©ºé—²ï¼ˆç¡®ä¿æ‰€æœ‰èµ„æºåŠ è½½å®Œæˆï¼‰
            try:
                await page.wait_for_load_state('networkidle', timeout=15000)
            except:
                # å¦‚æœè¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ
                pass
            
            # é¢å¤–ç­‰å¾…ç¡®ä¿æ¸²æŸ“å®Œæˆ
            await page.wait_for_timeout(1000)
            
            height = await page.evaluate('document.body.scrollHeight')
            await page.set_viewport_size({'width': 450, 'height': height + 50})
            await page.wait_for_timeout(500)
            
            # éªŒè¯å›¾ç‰‡æ˜¯å¦åŠ è½½ï¼ˆè°ƒè¯•ç”¨ï¼‰
            loaded_images = await page.evaluate("""
                () => {
                    const images = Array.from(document.images);
                    return {
                        total: images.length,
                        loaded: images.filter(img => img.complete && img.naturalHeight > 0).length,
                        failed: images.filter(img => img.complete && img.naturalHeight === 0).length
                    };
                }
            """)
            print(f"   å›¾ç‰‡åŠ è½½çŠ¶æ€: {loaded_images['loaded']}/{loaded_images['total']} æˆåŠŸ, {loaded_images['failed']} å¤±è´¥")
            
            # æˆªå›¾ï¼Œä½¿ç”¨é«˜è´¨é‡è®¾ç½®
            await page.screenshot(
                path=output_path, 
                full_page=True,
                type='png',
                clip=None  # ä½¿ç”¨full_pageæ—¶clipåº”ä¸ºNone
            )
            await browser.close()
        
        return output_path

    
    def html_to_image(self, html_path):
        """è½¬å›¾ç‰‡"""
        safe_name = sanitize_filename(self.json_data.get('chatName', 'æœªçŸ¥'))
        output_path = os.path.join(self.output_dir, f"{safe_name}_å¹´åº¦çƒ­è¯æŠ¥å‘Š.png")
        
        print("ğŸ–¼ï¸ è½¬æ¢ä¸ºå›¾ç‰‡...")
        try:
            result = asyncio.run(self._html_to_image_async(html_path, output_path))
            if result:
                print(f"âœ… å›¾ç‰‡: {output_path}")
                return output_path
        except Exception as e:
            print(f"âš ï¸ è½¬æ¢å¤±è´¥: {e}")
        
        return None
    
    def generate_user_personality_html(self):
        """ç”Ÿæˆç‹¬ç«‹çš„ç¾¤å‹æ€§æ ¼é”è¯„HTMLé¡µé¢"""
        if not self.user_representative_words:
            print("âŒ æ— ç¾¤å‹æ•°æ®")
            return None
        
        if not os.path.exists(self.template_dir):
            os.makedirs(self.template_dir)
        
        template_path = os.path.join(self.template_dir, 'user_personality_template.html')
        if not os.path.exists(template_path):
            print(f"âŒ æ¨¡æ¿ä¸å­˜åœ¨: {template_path}")
            return None
        
        env = Environment(
            loader=FileSystemLoader(self.template_dir),
            autoescape=select_autoescape(['html'])
        )
        env.filters['format_number'] = format_number
        env.filters['truncate_text'] = truncate_text
        env.filters['avatar_url'] = get_avatar_url
        
        template = env.get_template('user_personality_template.html')
        
        # å‡†å¤‡æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨å¤´åƒURLï¼ˆé€šè¿‡HTTPè®¿é—®æ—¶ï¼Œå¤–éƒ¨å›¾ç‰‡å¯ä»¥æ­£å¸¸åŠ è½½ï¼‰
        processed_users = []
        for user_info in self.user_representative_words:
            user_name = user_info['name']
            personality_comment = self.user_personality_comments.get(user_name, '')
            uin = user_info.get('uin', '')
            
            # ç›´æ¥ä½¿ç”¨å¤´åƒURLï¼ˆä¸å¹´åº¦æŠ¥å‘Šä¸€è‡´ï¼Œé€šè¿‡HTTPè®¿é—®æ—¶å¤–éƒ¨å›¾ç‰‡å¯ä»¥æ­£å¸¸åŠ è½½ï¼‰
            avatar_url = get_avatar_url(uin) if uin else 'https://q1.qlogo.cn/g?b=qq&nk=0&s=640'

            processed_users.append({
                'name': user_name,
                'uin': uin,
                'avatar': avatar_url,  # ä¿®å¤ï¼šä½¿ç”¨avatar_urlè€Œä¸æ˜¯avatar
                'words': user_info['words'],
                'stats': user_info.get('stats', {}),
                'personality_comment': personality_comment
            })
        
        data = {
            'chat_name': self.json_data.get('chatName', 'æœªçŸ¥ç¾¤èŠ'),
            'message_count': self.json_data.get('messageCount', 0),
            'user_personalities': processed_users
        }
        
        html_content = template.render(**data)
        
        safe_name = sanitize_filename(self.json_data.get('chatName', 'æœªçŸ¥'))
        html_path = os.path.join(self.personality_output_dir, f"{safe_name}_ç¾¤å‹æ€§æ ¼é”è¯„.html")
        
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… ç¾¤å‹é”è¯„HTML: {html_path}")
        return html_path
    
    async def _personality_html_to_image_async(self, html_path, output_path):
        """å¼‚æ­¥è½¬å›¾ç‰‡ - ç¾¤å‹é”è¯„ä¸“ç”¨ï¼ˆ900pxå®½åº¦ï¼Œé«˜æ¸…æ™°åº¦ï¼‰"""
        try:
            from playwright.async_api import async_playwright
        except ImportError:
            print("âŒ éœ€è¦: pip install playwright && playwright install chromium")
            return None
        
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            # ä½¿ç”¨ device_scale_factor=3 æé«˜åˆ†è¾¨ç‡ï¼ˆä¸å¹´åº¦æŠ¥å‘Šä¸€è‡´ï¼‰ï¼Œå®½åº¦è®¾ä¸º900px
            context = await browser.new_context(
                viewport={'width': 900, 'height': 1200},
                device_scale_factor=3,  # 3å€é«˜æ¸…æˆªå›¾ï¼Œä¸å¹´åº¦æŠ¥å‘Šä¸€è‡´
                # å…è®¸åŠ è½½å¤–éƒ¨èµ„æº
                ignore_https_errors=True
            )
            page = await context.new_page()
            
            # è®¾ç½®è¯·æ±‚æ‹¦æˆªï¼Œç¡®ä¿å¤–éƒ¨å›¾ç‰‡å¯ä»¥åŠ è½½ï¼ˆè™½ç„¶å¤´åƒå·²è½¬ä¸ºbase64ï¼Œä½†ä¿ç•™ä»¥é˜²ä¸‡ä¸€ï¼‰
            async def handle_route(route):
                request = route.request
                await route.continue_()
            
            await page.route('**/*', handle_route)
            
            # ä½¿ç”¨ file:// åè®®åŠ è½½æœ¬åœ°HTML
            file_url = f'file://{os.path.abspath(html_path).replace(os.sep, "/")}'
            await page.goto(file_url, wait_until='domcontentloaded', timeout=30000)
            
            # ç­‰å¾…æ‰€æœ‰å›¾ç‰‡çœŸæ­£åŠ è½½å®Œæˆï¼ˆåŒ…æ‹¬å¤´åƒï¼‰
            # ç”±äºå¤´åƒå·²è½¬æ¢ä¸ºbase64åµŒå…¥HTMLï¼ŒåŠ è½½ä¼šæ›´å¿«æ›´å¯é 
            print("   ç­‰å¾…å›¾ç‰‡åŠ è½½...")
            try:
                # æ›´å®Œå–„çš„å›¾ç‰‡åŠ è½½ç­‰å¾…é€»è¾‘
                await page.evaluate("""
                    async () => {
                        const images = Array.from(document.images);
                        if (images.length === 0) {
                            return;
                        }
                        
                        const promises = images.map((img) => {
                            return new Promise((resolve) => {
                                // å¦‚æœå›¾ç‰‡å·²ç»åŠ è½½å®Œæˆï¼ˆåŒ…æ‹¬base64å›¾ç‰‡ï¼‰
                                if (img.complete && img.naturalHeight !== 0) {
                                    resolve();
                                    return;
                                }
                                
                                // base64å›¾ç‰‡é€šå¸¸ç«‹å³åŠ è½½å®Œæˆ
                                if (img.src && img.src.startsWith('data:')) {
                                    // ç»™base64å›¾ç‰‡ä¸€ç‚¹æ—¶é—´æ¸²æŸ“
                                    setTimeout(() => resolve(), 100);
                                    return;
                                }
                                
                                // ç›‘å¬åŠ è½½æˆåŠŸ
                                img.onload = () => resolve();
                                
                                // ç›‘å¬åŠ è½½å¤±è´¥ï¼ˆä¹Ÿç»§ç»­ï¼Œé¿å…å¡ä½ï¼‰
                                img.onerror = () => {
                                    resolve();  // å¤±è´¥ä¹Ÿç»§ç»­
                                };
                                
                                // è¶…æ—¶ä¿æŠ¤ï¼ˆ3ç§’ï¼Œbase64å›¾ç‰‡åº”è¯¥å¾ˆå¿«ï¼‰
                                setTimeout(() => {
                                    resolve();
                                }, 3000);
                            });
                        });
                        
                        await Promise.all(promises);
                        
                        // é¢å¤–ç­‰å¾…ç¡®ä¿æ¸²æŸ“å®Œæˆ
                        await new Promise(resolve => setTimeout(resolve, 300));
                    }
                """)
            except Exception as e:
                print(f"   å›¾ç‰‡åŠ è½½ç­‰å¾…å‡ºç°å¼‚å¸¸ï¼ˆç»§ç»­æ‰§è¡Œï¼‰: {e}")
            
            # ç­‰å¾…ç½‘ç»œç©ºé—²ï¼ˆç¡®ä¿æ‰€æœ‰èµ„æºåŠ è½½å®Œæˆï¼‰
            # base64å›¾ç‰‡ä¸éœ€è¦ç½‘ç»œï¼Œæ‰€ä»¥è¿™ä¸ªç­‰å¾…ä¼šå¾ˆå¿«
            try:
                await page.wait_for_load_state('networkidle', timeout=10000)
            except:
                # å¦‚æœè¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œï¼ˆbase64å›¾ç‰‡ä¸éœ€è¦ç½‘ç»œï¼‰
                pass
            
            # é¢å¤–ç­‰å¾…ç¡®ä¿æ¸²æŸ“å®Œæˆ
            await page.wait_for_timeout(500)
            
            # è·å–å®é™…å†…å®¹é«˜åº¦
            height = await page.evaluate('document.body.scrollHeight')
            await page.set_viewport_size({'width': 900, 'height': height + 50})
            
            # å†æ¬¡ç­‰å¾…ç¡®ä¿å¸ƒå±€ç¨³å®š
            await page.wait_for_timeout(500)
            
            # éªŒè¯å›¾ç‰‡æ˜¯å¦åŠ è½½ï¼ˆè°ƒè¯•ç”¨ï¼‰
            loaded_images = await page.evaluate("""
                () => {
                    const images = Array.from(document.images);
                    return {
                        total: images.length,
                        loaded: images.filter(img => img.complete && img.naturalHeight > 0).length,
                        failed: images.filter(img => img.complete && img.naturalHeight === 0).length
                    };
                }
            """)
            print(f"   å›¾ç‰‡åŠ è½½çŠ¶æ€: {loaded_images['loaded']}/{loaded_images['total']} æˆåŠŸ, {loaded_images['failed']} å¤±è´¥")
            
            # æˆªå›¾ï¼Œä½¿ç”¨é«˜è´¨é‡è®¾ç½®
            await page.screenshot(
                path=output_path, 
                full_page=True,
                type='png',
                clip=None  # ä½¿ç”¨full_pageæ—¶clipåº”ä¸ºNone
            )
            await browser.close()
        
        return output_path
    
    def user_personality_html_to_image(self, html_path):
        """å°†ç¾¤å‹æ€§æ ¼é”è¯„HTMLè½¬æ¢ä¸ºå›¾ç‰‡"""
        safe_name = sanitize_filename(self.json_data.get('chatName', 'æœªçŸ¥'))
        output_path = os.path.join(self.personality_output_dir, f"{safe_name}_ç¾¤å‹æ€§æ ¼é”è¯„.png")
        
        print("ğŸ–¼ï¸ è½¬æ¢ä¸ºå›¾ç‰‡...")
        try:
            result = asyncio.run(self._personality_html_to_image_async(html_path, output_path))
            if result:
                print(f"âœ… å›¾ç‰‡: {output_path}")
                return output_path
        except Exception as e:
            print(f"âš ï¸ è½¬æ¢å¤±è´¥: {e}")
        
        return None
    
    def generate(self, auto_select=False, ai_select=False, non_interactive=False, generate_image=False, enable_ai=False):
        """ç”ŸæˆæŠ¥å‘Š
        
        å‚æ•°:
            auto_select: è‡ªåŠ¨é€‰æ‹©å‰10ä¸ªï¼ˆç®€å•æ¨¡å¼ï¼‰
            ai_select: ä½¿ç”¨AIæ™ºèƒ½é€‰è¯ï¼ˆä»å‰200ä¸ªä¸­é€‰å‡ºæœ€æœ‰è¶£çš„10ä¸ªï¼‰
            non_interactive: éäº¤äº’æ¨¡å¼
            generate_image: æ˜¯å¦ç”Ÿæˆå›¾ç‰‡
            enable_ai: æ˜¯å¦å¯ç”¨AIé”è¯„
        """
        if not self.json_data:
            print("âŒ æ— æ•°æ®")
            return None, None
        
        # AI æ™ºèƒ½é€‰è¯æ¨¡å¼
        if ai_select:
            print("\n" + "=" * 60)
            print("ğŸ¤– AIæ™ºèƒ½é€‰è¯æ¨¡å¼")
            print("=" * 60)
            
            top_words = self.json_data.get('topWords', [])
            if not top_words:
                print("âŒ æ— çƒ­è¯æ•°æ®")
                return None, None
            
            # åˆå§‹åŒ–AIé€‰è¯å™¨
            if not self.ai_selector:
                self.ai_selector = AIWordSelector()
            
            # AIé€‰è¯
            self.selected_words = self.ai_selector.select_words(top_words, top_n=200)
            
            if not self.selected_words:
                print("âš ï¸ AIé€‰è¯å¤±è´¥ï¼Œæ”¹ç”¨è‡ªåŠ¨é€‰æ‹©å‰10ä¸ª")
                self.selected_words = top_words[:10]
        
        # ç®€å•è‡ªåŠ¨é€‰æ‹©æ¨¡å¼
        elif auto_select or non_interactive:
            self.selected_words = self.json_data.get('topWords', [])[:10]
            print(f"ğŸ“ è‡ªåŠ¨é€‰æ‹©å‰10ä¸ªçƒ­è¯")
        
        # äº¤äº’é€‰æ‹©æ¨¡å¼
        else:
            if not self.display_words_for_selection():
                return None, None
        
        if not self.selected_words:
            return None, None, None, None
        
        # AIé”è¯„
        self._generate_ai_comments(enable_ai)
        
        # ç¾¤å‹æ€§æ ¼å’Œç”¨è¯é”è¯„
        self._generate_user_personality_comments(enable_ai)
        
        print("\nğŸ¨ ç”ŸæˆæŠ¥å‘Š...")
        html_path = self.generate_html()
        if not html_path:
            return None, None, None, None
        
        img_path = None
        if generate_image:
            img_path = self.html_to_image(html_path)
        
        # ç”Ÿæˆç‹¬ç«‹çš„ç¾¤å‹æ€§æ ¼é”è¯„é¡µé¢
        personality_html_path = None
        personality_img_path = None
        if self.user_representative_words:
            print("\nğŸ­ ç”Ÿæˆç¾¤å‹æ€§æ ¼é”è¯„é¡µé¢...")
            personality_html_path = self.generate_user_personality_html()
            if personality_html_path and generate_image:
                personality_img_path = self.user_personality_html_to_image(personality_html_path)
        
        # è¿”å›ä¸»æŠ¥å‘Šå’Œç¾¤å‹é”è¯„çš„è·¯å¾„
        # æ ¼å¼: (ä¸»æŠ¥å‘Šhtml, ä¸»æŠ¥å‘Šå›¾ç‰‡, ç¾¤å‹é”è¯„html, ç¾¤å‹é”è¯„å›¾ç‰‡)
        return html_path, img_path, personality_html_path, personality_img_path


def interactive_generate(json_path=None, analyzer=None):
    """äº¤äº’å¼é€‰è¯ç”Ÿæˆ"""
    gen = ImageGenerator(analyzer=analyzer, json_path=json_path)
    gen.enabled = True
    result = gen.generate(auto_select=False, enable_ai=True, generate_image=True)
    # å…¼å®¹æ—§ä»£ç ï¼šå¦‚æœè¿”å›4ä¸ªå€¼ï¼Œåªè¿”å›å‰2ä¸ª
    if result and len(result) == 4:
        html_path, img_path, _, _ = result
        return html_path, img_path
    return result


def auto_generate(json_path=None, analyzer=None):
    """è‡ªåŠ¨é€‰æ‹©å‰10ä¸ªç”Ÿæˆ"""
    gen = ImageGenerator(analyzer=analyzer, json_path=json_path)
    gen.enabled = True
    result = gen.generate(auto_select=True, enable_ai=True, generate_image=True)
    # å…¼å®¹æ—§ä»£ç ï¼šå¦‚æœè¿”å›4ä¸ªå€¼ï¼Œåªè¿”å›å‰2ä¸ª
    if result and len(result) == 4:
        html_path, img_path, _, _ = result
        return html_path, img_path
    return result


def ai_generate(json_path=None, analyzer=None):
    """AIæ™ºèƒ½é€‰è¯ç”Ÿæˆ"""
    gen = ImageGenerator(analyzer=analyzer, json_path=json_path)
    gen.enabled = True
    result = gen.generate(ai_select=True, enable_ai=True, generate_image=True)
    # å…¼å®¹æ—§ä»£ç ï¼šå¦‚æœè¿”å›4ä¸ªå€¼ï¼Œåªè¿”å›å‰2ä¸ª
    if result and len(result) == 4:
        html_path, img_path, _, _ = result
        return html_path, img_path
    return result


if __name__ == '__main__':
    import glob
    
    print("=" * 60)
    print("ğŸ–¼ï¸  æŠ¥å‘Šç”Ÿæˆå™¨ ")
    print("=" * 60)
    
    if len(sys.argv) > 1:
        json_path = sys.argv[1]
    else:
        json_files = glob.glob('*_åˆ†æç»“æœ.json')
        if not json_files:
            print("âŒ æœªæ‰¾åˆ°JSONæ–‡ä»¶")
            sys.exit(1)
        if len(json_files) == 1:
            json_path = json_files[0]
        else:
            for i, f in enumerate(json_files, 1):
                print(f"  {i}. {f}")
            json_path = json_files[int(input("é€‰æ‹©: ")) - 1]
    
    print(f"\nğŸ“‚ {json_path}")
    
    print("\né€‰æ‹©æ¨¡å¼:")
    print("  1. äº¤äº’é€‰è¯ - æ‰‹åŠ¨é€‰æ‹©10ä¸ªçƒ­è¯")
    print("  2. è‡ªåŠ¨å‰10 - ç›´æ¥é€‰æ‹©å‰10ä¸ª")
    print("  3. AIæ™ºèƒ½é€‰è¯ - è®©AIä»å‰200ä¸ªä¸­æŒ‘é€‰æœ€æœ‰è¶£çš„10ä¸ª ğŸ¤–")
    
    mode = input("\nè¯·é€‰æ‹© [1/2/3]: ").strip()
    
    if mode == '3':
        result = ai_generate(json_path=json_path)
    elif mode == '2':
        result = auto_generate(json_path=json_path)
    else:
        result = interactive_generate(json_path=json_path)
    
    print("\n" + "=" * 60)
    if result:
        if len(result) == 4:
            html_path, img_path, personality_html, personality_img = result
            if html_path:
                print(f"ğŸ“„ ä¸»æŠ¥å‘ŠHTML: {html_path}")
            if img_path:
                print(f"ğŸ–¼ï¸ ä¸»æŠ¥å‘Šå›¾ç‰‡: {img_path}")
            if personality_html:
                print(f"ğŸ­ ç¾¤å‹é”è¯„HTML: {personality_html}")
            if personality_img:
                print(f"ğŸ–¼ï¸ ç¾¤å‹é”è¯„å›¾ç‰‡: {personality_img}")
        else:
            html_path, img_path = result
            if html_path:
                print(f"ğŸ“„ {html_path}")
            if img_path:
                print(f"ğŸ–¼ï¸ {img_path}")
